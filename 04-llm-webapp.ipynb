{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM app\n",
    "\n",
    "For this example we will use a chainlit llm chat app, as the base. \n",
    "\n",
    "\n",
    "The idea will then be to add observability to the app, so that we can see how the app is performing and how it is being used. and then use this telemetry to display metrics for our app. \n",
    "\n",
    "Both business, operational, and development metrics.\n",
    "\n",
    "For this we will use the following libraries:\n",
    "- [Chainlit](https://chainlit.io/)\n",
    "  \n",
    "\n",
    "We also need to create a azure openai resource and deploy a model if you haven't already. you can either do it by hand via the portal or by using the bicep from part 02, This bicep also includes the deployment of a model, and the azure monitor stack. \n",
    "\n",
    "Your goal for this use-case is to implement the opentelemetry stack, where you should capture the following.\n",
    "\n",
    "* Log any exceptions that occur in the app.\n",
    "* Log the time it takes to process a request.\n",
    "* How long does the model take to respond.\n",
    "* How long does the vector database take to respond.\n",
    "* How many Tokens are being used by any given request.\n",
    "\n",
    "All the logs should contain the following information(when relevant)\n",
    "* Which model we are using (gpt4, gpt35, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To run the app, you need to have the following environment variables in the .env file. you can find them in the ai foundry at ai.azure.com\n",
    "\n",
    "```bash\n",
    "AZURE_OPENAI_API_KEY=\n",
    "AZURE_OPENAI_ENDPOINT=https://oai-yourdeploymentname-prod.openai.azure.com/\n",
    "```\n",
    "\n",
    "You also need need to install the pip packages in the 04a/requirements.txt file.\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "and then run the app with the following command.\n",
    "\n",
    "```bash\n",
    "chainlit run app.py -w\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint**  During the implementation, it is a good idea to keep an eye on the transaction search in application insight, as that gives you near real time logs, so that you can see the progress, and if the telemetry is being sent correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next steps\n",
    "\n",
    "Now that we have a application with telemetry, we can start to look at the data we are collecting, and build a dashboard around it.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
