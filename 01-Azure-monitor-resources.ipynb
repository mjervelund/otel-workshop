{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure monitor resources basics\n",
    "\n",
    "Within the Azure ecosystem there are quite a few components that can be used to monitor applications and services. These components are part of the Azure Monitor stack, which is a set of services and tools that provide monitoring, diagnostics, and alerting capabilities for Azure resources and applications.\n",
    "\n",
    "![Azure Monitor](.files/azure_monitor.png)\n",
    "\n",
    "Within Azure monitor we have the ability query logs, create alerts and build dashboards. These features are all available in the azure portal, but also using the Azure CLI or Bicep templates.\n",
    "\n",
    "All the services we need in azure are defined via Bicep, but can also be deployed in a Azure portal UI, or via az cli.\n",
    "\n",
    "\n",
    "For the workshop today we will be using the following resources:\n",
    "- **Log Analytics workspace**: This is a service within Azure Monitor that allows you to collect and analyze log data from various sources. It provides a powerful query language (Kusto Query Language) for analyzing log data and creating custom dashboards and alerts.\n",
    "- **Application Insights**: This is a service within Azure Monitor that provides application performance monitoring and diagnostics. It collects telemetry data from your applications, including request rates, response times, and failure rates, and provides insights into the performance and usage of your applications.\n",
    "\n",
    "\n",
    "Let's try to deploy these resources, you can choose to either do it via the Azure portal or using Bicep templates. Follow the steps below if you don't have the Azure CLI installed yet.\n",
    "<details>\n",
    "  <summary>How to install the Azure CLI</summary>\n",
    "\n",
    "**Windows**\n",
    "```Powershell\n",
    "winget install --exact --id Microsoft.AzureCLI\n",
    "```\n",
    "\n",
    "**Ubuntu/Linux with APT**\n",
    "```bash\n",
    "sudo apt-get update && sudo apt-get install azure-cli -y\n",
    "```\n",
    "\n",
    "**MacOS with Homebrew**\n",
    "```bash\n",
    "brew update && brew install azure-cli\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the azcli, you can log in to your Azure account using the following command:\n",
    "\n",
    "```bash\n",
    "az login\n",
    "```\n",
    "\n",
    "Then select the subscription you want to use for this workshop:\n",
    "\n",
    "```bash\t\n",
    "az account set --subscription \"YOUR_SUBSCRIPTION_OID\"\n",
    "```\n",
    "\n",
    "Let's check if everything is working as expected by creating a resource group in the swedencentral region that we'll use for this workshop.\n",
    "\n",
    "```bash\n",
    "az group create --name \"rg-observabilityworkshop-dev\" --location 'swedencentral'\n",
    "```\n",
    "\n",
    "**Deploy Log Analytics workspace and Application Insights**\n",
    "\n",
    "Let's create a Log Analytics workspace and Application Insights resource in the resource group we just created. You can use either the azcli and the following commands, The Bicep files in the 01 folder or using the portal. however it is recommended to use the Bicep files to as we will reuse them in the nest sections.\n",
    "\n",
    "<details>\n",
    "  <summary>Using the Azure CLI</summary>\n",
    "\n",
    "```powershell\n",
    "\n",
    "$UserInitials = \"ABCD\" # Replace with your initials\n",
    "\n",
    "$Timestamp = Get-Date -Format \"yyMMddHHmmss\"\n",
    "\n",
    "# Microsoft Observability Workshop - msows\n",
    "$SystemName = \"msows${UserInitials}\"\n",
    "$Environment = \"dev\"\n",
    "$Location = \"swedencentral\"\n",
    "\n",
    "$ResourceGroupName = \"rg-observabilityworkshop-dev\"\n",
    "$workspacename = \"log-${SystemName}-dev\"\n",
    "$appiName = \"appi-${SystemName}-dev\"\n",
    "az monitor log-analytics workspace create --name $workspacename --resource-group $ResourceGroupName --location 'swedencentral'\n",
    "az monitor app-insights component create --app $appiName --workspace $workspacename --location 'swedencentral' --kind other -g $ResourceGroupName --application-type other --retention-time 120\n",
    "```\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "  <summary>Using Bicep</summary>\n",
    "\n",
    "There is a Deploy.ps1 file in the 01 folder that you can use to deploy the resources, that is nearly identical to this code\n",
    "\n",
    "```powershell\n",
    "$UserInitials  = \"ABCD\" # Replace with your initials\n",
    "\n",
    "$Timestamp = Get-Date -Format \"yyMMddHHmmss\"\n",
    "\n",
    "# Microsoft Observability Workshop - msows\n",
    "$SystemName = \"msows${UserInitials}\"\n",
    "$Environment = \"dev\"\n",
    "$Location = \"swedencentral\"\n",
    "\n",
    "$ResourceGroupName = \"rg-observabilityworkshop-dev\"\n",
    "\n",
    "az deployment group create `\n",
    "    --name \"ObservabilityWorkshop${Timestamp}\" `\n",
    "    --mode \"Complete\" `\n",
    "    --resource-group $ResourceGroupName `\n",
    "    --template-file ./01/main.bicep `\n",
    "    --parameters `\n",
    "        env=$Environment `\n",
    "        systemName=$SystemName `\n",
    "        location=$Location `\n",
    "        deploymentSuffix=$Timestamp\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, you should now have the following resources in your resource group:\n",
    "- **Log Analytics workspace**\n",
    "- **Application Insights**\n",
    "\n",
    "Now that we've deployed our azure resources, let's take a look at them, and what functionality they provide out of the box.\n",
    "\n",
    "**Log Analytics workspace**\n",
    "\n",
    "Within the Log analytics workspace we have a few different features that we can use to collect, query and analyze the raw logs, I'll just 4 of them that you might find useful:\n",
    "\n",
    "* **Logs** From the logs blade we can query the logs using Kusto Query Language (KQL). You will generally use this to investigate issues deeper, or write queries that you can use in dashboards or for alerts. The logs blade is also where you can create custom queries and save them for later use.\n",
    "* **Tables** Overview of what tables are available in the workspace, and the ability to update retention periods. This is a good place to start if you want to see what data is available for querying.\n",
    "* **Agents** Agents are application that you can run on windows or linux machines to collect logs and send them to the Log Analytics workspace. This is a good way to collect logs from on-premises machines, or from virtual machines that are not running in Azure. They can also serve as proxies machines that can't access the internet directly.\n",
    "* **Data Export rules** Data export rules are used to export data from the Log Analytics workspace to other Azure services, such as Azure Storage or Event Hubs. This is a good way to archive logs, or to send logs to other services for further processing.\n",
    "\n",
    "**Application Insights**\n",
    "Application Insights is a service within Azure Monitor that provides application performance monitoring and diagnostics. It receives telemetry data from your applications, and provides a few more features to display your logs, and investigate how they are collected.\n",
    "\n",
    "**Application map**: The application map is a visual representation of the components in your application and how they are connected. It shows the dependencies between components, and visualizes the latencies, number of requests, and failure rates for each component. this is great for a quick overview of your entire platform.\n",
    "\n",
    "**Live metrics**: Operational metrics about your web servers, such as CPU and memory usage, request rates, and response times. and dependency calls. \n",
    "\n",
    "**Transaction search**\n",
    "The transaction search is a powerful tool that allows you to search for specific requests and dependencies in your application. You can filter by time range, request URL, response code, and other parameters. and investigate the request end to end to debug issues. This is a great tool for investigating issues in production, as it allows you to see the entire request flow and identify where the issue occurred.\n",
    "\n",
    "<img src=\".files/appi_transaction_search_query.png\" width=\"600\">\n",
    "\n",
    "you can pres on any log entry to show the end to end transaction, and see the entire request flow, as well as all custom dimensions of the log entries.\n",
    "\n",
    "<img src=\".files/appi_transaction_search_endtoend.png\" width=\"600\">\n",
    "\n",
    "\n",
    "**Availability**: The Availability feature in Application insight allow you to create health check probes via HTTP(s) so see if your applications is healthy and responding, if the certificate is about the expire, and optionally create alerts based on this.\n",
    "\n",
    "\n",
    "<img src=\".files/appi_Availability.png\" width=\"600\">\n",
    "\n",
    "**Failure analysis**:\n",
    "Failure analysis gives you quick insight into errors, exceptions and failed requests in your application. It shows you the number of failures, the failure rate, and the most common failure types. This is a great tool for identifying issues in your application and troubleshooting them.\n",
    "\n",
    "\n",
    "**Performance analysis**: \n",
    "The performance analysis feature in Application Insights allows you to analyze the response times of your application and identify performance bottlenecks. It shows you the average response time, the number of requests, and the most common response times. This is a great tool for identifying performance issues in your application and troubleshooting them. eg if you have a slow dependency call, or if your have poorly optimized queries in your application.\n",
    "\n",
    "<img src=\".files/appi_preformance_analysis.png\" width=\"600\">\n",
    "\n",
    "\n",
    "#### Next steps\n",
    "We can now take a look at collecting telemetry from azure services, Jump to the next section.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
